{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docler Holding - Machine Learning homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Dataset exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset exploration\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import Image\n",
    "Image(\"image/formulation.png\")\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='../data', train=True,\n",
    "                                        download=True, transform=transforms.ToTensor())\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                          batch_size=4,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  \n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, labels = next(iter(trainloader))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out)\n",
    "print('Label:', '    '.join('%5s' % classes[labels[j]] for j in range(4)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Takeaways__:\n",
    "* Similar to Imagenet\n",
    "* Smaller, lower resolution images\n",
    "* Balanced classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection\n",
    "\n",
    "__Requirements__: \n",
    "   * fast to train, fast prediction \n",
    "   * good accuracy\n",
    "   * off the shelf method\n",
    "   * has pretrained weights on ImageNet\n",
    "   * scalable to bigger model\n",
    "   \n",
    "Main source for model comparison: Benchmark analysis of representative deep neural network architectures (Bianco et al., 2018)\n",
    "                     \n",
    "#### VGG\n",
    "* VGG is widely used (results are easy to compare)\n",
    "* elegant structure\n",
    "* too many parameters\n",
    "* slow to train\n",
    "\n",
    "#### ResNet\n",
    "* thinner and deeper than VGG, less parameters\n",
    "* better accuracy than VGG, AlexNet and GoogleNet \n",
    "* has fairly even accuracy scores across categories (An Analysis Of Convolutional Neural Networks For Image Classification, (Sharma et al., 2018)) --> Important for us\n",
    "* easy to scale, has many variants\n",
    "\n",
    "#### MobileNet-V2\n",
    "\n",
    "* MobileNetV2, usually less accurate than ResNet50\n",
    "* Our object in this project is not to be able to run it on mobile device\n",
    "\n",
    "#### DenseNet\n",
    "* Could be an alternative, comparable accuracy to ResNet\n",
    "* For similar accuracy, more parameters are required\n",
    "* Longer inference time than similar-performing ResNet\n",
    "\n",
    "\n",
    "\n",
    "## Selected architecture: ResNet\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Subset selection\n",
    "\n",
    "__What is an informative subset of the training data?__\n",
    "\n",
    "--> Core-set selection problem\n",
    "\n",
    "How do we select a subset of the data so the prediction accuracy remains as high as possible?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/formulation.png\" width=\"650\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selection via proxy: Efficient data selection for deep learning (Coleman et al., 2019)\n",
    "\n",
    "\n",
    "Pros:\n",
    "* computationally efficient: \n",
    "* small proxy model, \n",
    "* good Spearman correlation between small and big models on metrics like uncertainty \n",
    "\n",
    "Main steps: \n",
    "1. Train a smaller proxy model\n",
    "2. Select the subset of the data that is \"hard\" based on some criteria\n",
    "3. Train bigger model on the core-set\n",
    "\n",
    "\n",
    "__We could use ResNet-18 as a proxy model and train ResNet-50 on the Subset__\n",
    "\n",
    "\n",
    "Selection algorithm: forgetting events (An empirical study of example forgetting during deep learning (Toneva et al, 2019))\n",
    "Main idea: \n",
    "1. During training for each sample calculate how often a model learns and than forgets how to classify it correctly (forgetting event)\n",
    "2. Select the hardest examples: samples that have never been learnt or forgotten the most times\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/forgetting_events.png\" width=\"320\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Network modifications\n",
    "\n",
    "1. I've started from a pretrained network on the ImageNet class and modified the decision making MLP, so it has 11 output neurons (10 for prediction, 1 for the ones). \n",
    "\n",
    "2. If trained with freezed weights, I set requires_grad=False for all weights in the convolutional architecture and skip connections, so only the decision-making MLP layers are trainable. \n",
    "\n",
    "3. I've scaled up the CIFAR-10 images to 224x244 RGB pixels, so the inputs will resemble the ImageNet inputs (with lower resolution of course). \n",
    "\n",
    "4. I created a custom model from an existing base neural network. It splits the output activation layer into two streams. The first 10 neurons are responsible for the class prediction, the last one is clamped from below and above to 1.\n",
    "\n",
    "5. Later we only calculate the loss for (and backprop through) the prediction neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def set_parameter_requires_grad(model, freeze_weights):\n",
    "    if freeze_weights:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "class MyModel(torch.nn.Module):\n",
    "    # We initialize from a base model\n",
    "    def __init__(self, base_model):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.base_model = base_model\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.base_model(x)\n",
    "\n",
    "        # We split output activations to 2 streams and clamp the last neuron from below and above\n",
    "        predictions = out[:, :-1]\n",
    "        ones = out[:, -1].clamp(min=1, max=1)\n",
    "        \n",
    "        return predictions, ones\n",
    "\n",
    "\n",
    "def initialize_model(model_type, num_classes, use_pretrained, freeze_weights, dropout, device):\n",
    "    \n",
    "\n",
    "    model = None\n",
    "\n",
    "    if model_type == \"resnet18\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model = models.resnet18(pretrained = use_pretrained)\n",
    "    elif model_type == 'resnet50':\n",
    "        \"\"\" Resnet50\n",
    "        \"\"\"\n",
    "        model = models.resnet50(pretrained = use_pretrained)\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model type, exiting...\")\n",
    "        exit()\n",
    "    \n",
    "    set_parameter_requires_grad(model, freeze_weights)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    if dropout:     \n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 256),\n",
    "            nn.Dropout(),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.Dropout(),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_classes+1)\n",
    "            )\n",
    "    else:\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_classes+1)\n",
    "            )\n",
    "\n",
    "    \n",
    "    # We add the extra strem for ones \n",
    "    extended_model = MyModel(model)\n",
    "\n",
    "    extended_model = extended_model.to(device)\n",
    "\n",
    "    return extended_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = models.resnet50()\n",
    "my_model = MyModel(base_model)\n",
    "\n",
    "# testing ones during training time\n",
    "my_model.train()\n",
    "inputs, labels = next(iter(trainloader))\n",
    "predictions, ones = my_model(inputs)\n",
    "assert(len(ones) == len(predictions)) \n",
    "assert(ones.dtype == predictions.dtype)\n",
    "\n",
    "print(f'At training time ones = {ones} \\n')\n",
    "\n",
    "# testing ones during inference time\n",
    "\n",
    "my_model.eval()\n",
    "inputs, labels = next(iter(trainloader))\n",
    "predictions, ones = my_model(inputs)\n",
    "assert(len(ones) == len(predictions)) \n",
    "assert(ones.dtype == predictions.dtype)\n",
    "\n",
    "print(f'At test time ones = {ones}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Training, optimization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the proxy model (ResNet-18)\n",
    "\n",
    "\n",
    "\n",
    "__Best results__:\n",
    "\n",
    "\n",
    "* Preloaded weights (previously trained on ImageNet\n",
    "* Data augmentation: random cropping and horizontal flipping of training images (makes the task much harder)\n",
    "* Normalizing images (same way as they were normalized while training on ImageNet)\n",
    "* All weights are trainable\n",
    "* 20 epochs are enough for convergence\n",
    "* 92.1% test accuracy\n",
    "* I used this model's behaviour as input for the subset selection algorithms\n",
    "\n",
    "\n",
    "\n",
    "__ResNet-50__: \n",
    "\n",
    "I trained the bigger model on the original dataset, for sanity check and later comparison\n",
    "\n",
    "\n",
    "* 93.0% test accuracy\n",
    "* trained for 80 epochs\n",
    "* preloaded weights\n",
    "* no weight freezing\n",
    "\n",
    "* sanity comparison: 93.0% for Resnet-18, 93.6% for ResNet-50 (https://github.com/kuangliu/pytorch-cifar)\n",
    "* --> ResNet-18 is a good proxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/proxy.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forgetting events stats\n",
    "\n",
    "* Majority of pictures were forgotten 1x, 2x or 3x \n",
    "* 103 images were never learnt\n",
    "* 1k forgetting events subset will consist of images that have never been classified correctly(~10%) and images that have been forgotten 6,7 or 8 times.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/forgetting_hist.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### forgetting events selection\n",
    "* 35% test accuracy\n",
    "* overfitting\n",
    "* looks poor, can we do better?\n",
    "* I have tried resuming the training, no significant change in result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/fe.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__random selection__\n",
    "* always good to check against random\n",
    "* much higher accuracy\n",
    "* still overfits\n",
    "* Why could it be? --> hardest 1k examples may be too hard for the model the get a good understanding of the categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/random.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__reverse forgetting events__\n",
    "* Why not try learning from the easiest examples\n",
    "* best performance so far\n",
    "* still overfits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/rev_fe.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning, combattig overfitting ##\n",
    "\n",
    "* Training accuracy is high, but train-validation gap is big --> let's try to combat overfitting\n",
    "* Freezing all convolutional layers, only finetuning the fc layers\n",
    "* Better accuracy\n",
    "* Still overfits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/rev_fe_freeze.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Let's try even more regularization__\n",
    "* Adding dropout layers to the linear layers in fc\n",
    "* less overfitting but accuracy drops\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/freeze_dropout.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Summary of accuracy scores of different models and selection methods__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/model_comparison.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other KPIs\n",
    "\n",
    "__Training times__:\n",
    "\n",
    "Disclaimer: tests were conducted with Google Colab's GPU's. There is no way to choose what type of GPU you can connect to at any given time (you might get different kind of gpu at every time you connet), so measurements can be unreliable and should be taken as proxy\n",
    "\n",
    "On the original CIFAR-10 Dataset\n",
    "* Proxy modell (ResNet18 for less epochs): 1h40m\n",
    "* ResNet-50: 5h52m\n",
    "\n",
    "Selection times (average of 3 runs)\n",
    "* forgetting_events: 8.3s\n",
    "* reverse_forgetting events 9.1s\n",
    "* random 0.8s\n",
    "\n",
    "Training on the 1k core-set (used the best perfroming _rev_fe_freeze_ model)\n",
    "* 53m \n",
    "\n",
    "Inference time (_rev_fe_freeze_ ):\n",
    "* on cpu: 313 ms\n",
    "* on gpu: 17 ms \n",
    "(used info and code from here to measure gpu inference: https://towardsdatascience.com/the-correct-way-to-measure-inference-time-of-deep-neural-networks-304a54e5187f)\n",
    "\n",
    "\n",
    "__Model size__:\n",
    "96,5 MB\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There should be no object recognition project without testing it on your own image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "import PIL.Image as Image\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "transform_eval = transforms.Compose(\n",
    "    [transforms.Resize(256),\n",
    "     transforms.CenterCrop(224),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "\n",
    "\n",
    "def try_your_picture(pic_name):\n",
    "    \n",
    "    test_model = initialize_model(\"resnet50\", 10, False, False, False, 'cpu')\n",
    "    test_model.load_state_dict(torch.load(\"model/trained_model.pth\", map_location=torch.device('cpu')))\n",
    "    test_model.eval()\n",
    "    \n",
    "    im = Image.open('test_pics/' + pic_name)\n",
    "    scale_to_show = transforms.Resize(250)\n",
    "    scaled = scale_to_show(im)\n",
    "\n",
    "    down_scale = transforms.Resize((32, 32))\n",
    "    im = transform_eval(down_scale(im)) \n",
    "    \n",
    "    out, ones = test_model(im.unsqueeze(0))\n",
    "    _, pred = torch.max(out, 1)\n",
    "    print(f\"predicted: {classes[int(pred)]}\")\n",
    "    display(scaled)\n",
    "    \n",
    "    \n",
    "try_your_picture('borisz.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) 80 hours project\n",
    "\n",
    "* Freezing only parts of the convolutional backbone, make upper layers trainable\n",
    "* L2, lasso regularization\n",
    "* Testing different model architecture, e.g. DenseNet\n",
    "* Hiperparameter optimization: learning rate, different optimizer(SGD, RMSProp)\n",
    "* Trying out other Subset selection methods (least confidence uncertainty sampling, max entropy sampling, greedy k-means)\n",
    "* Evaluation metrics: per class accuracy, top_k_accuracy, measuring throughput\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Model deployment\n",
    "\n",
    "Building a Docker image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
